import streamlit as st
from PIL import Image
import torch
import numpy as np
from transformers import CLIPModel, CLIPProcessor
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import io
import base64
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰",
    page_icon="ğŸ”",
    layout="wide"
)

# ImageSimilarityFinder í´ë˜ìŠ¤
class ImageSimilarityFinder:
    def __init__(self):
        self.model = None
        self.processor = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    @st.cache_resource
    def load_model(_self):
        """ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        model.to(_self.device)
        return model, processor
    
    def get_image_embedding(self, image):
        """ì´ë¯¸ì§€ì˜ ì„ë² ë”© ë²¡í„° ìƒì„±"""
        if self.model is None or self.processor is None:
            self.model, self.processor = self.load_model()
        
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        else:
            image = image.convert('RGB')
            
        inputs = self.processor(images=image, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            embedding = self.model.get_image_features(**inputs)
        
        return embedding.cpu().numpy()

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if 'saved_photos' not in st.session_state:
    st.session_state.saved_photos = []
if 'saved_count' not in st.session_state:
    st.session_state.saved_count = 0
if 'image_finder' not in st.session_state:
    st.session_state.image_finder = ImageSimilarityFinder()

# í—¤ë”
st.title("ğŸ” AI ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
st.markdown("**CLIP ëª¨ë¸ ê¸°ë°˜ ì§€ëŠ¥í˜• ì´ë¯¸ì§€ ë§¤ì¹­**")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    st.metric("ì €ì¥ëœ ì´ë¯¸ì§€", f"{len(st.session_state.saved_photos)}ì¥")
    
    device_info = "ğŸŸ¢ GPU" if torch.cuda.is_available() else "ğŸ”µ CPU"
    st.info(f"ì—°ì‚° ì¥ì¹˜: {device_info}")
    
    st.markdown("---")
    
    # ëª¨ë“œ ì„ íƒ
    mode = st.radio(
        "ëª¨ë“œ ì„ íƒ",
        ["ğŸ“¸ ì‘ê°€ ëª¨ë“œ", "ğŸ” ì´ìš©ì ëª¨ë“œ"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    st.caption("ğŸ’¡ ì‘ê°€ ëª¨ë“œ: ì‚¬ì§„ ì—…ë¡œë“œ ë° ì €ì¥")
    st.caption("ğŸ’¡ ì´ìš©ì ëª¨ë“œ: ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰")

# ==========================================
# ì‘ê°€ ëª¨ë“œ
# ==========================================
if mode == "ğŸ“¸ ì‘ê°€ ëª¨ë“œ":
    st.markdown("### ğŸ“¸ ì‚¬ì§„ ì—…ë¡œë“œ ë° AI ë¶„ë¥˜")
    st.info("ğŸ’¡ ì—¬ëŸ¬ ì¥ì˜ ì‚¬ì§„ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ê³  ìœ„ì¹˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”. AIê°€ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "ì‚¬ì§„ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        key="photographer_upload"
    )
    
    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)}ì¥ì˜ ì‚¬ì§„ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ì—…ë¡œë“œëœ ì‚¬ì§„ í‘œì‹œ
        st.markdown("### ğŸ“· ì—…ë¡œë“œëœ ì‚¬ì§„")
        
        # ì‚¬ì§„ì„ 4ê°œì”© ë‚˜ëˆ ì„œ í‘œì‹œ
        cols = st.columns(4)
        photo_data = []
        
        for idx, uploaded_file in enumerate(uploaded_files):
            col = cols[idx % 4]
            
            with col:
                # ì´ë¯¸ì§€ í‘œì‹œ
                image = Image.open(uploaded_file)
                st.image(image, use_container_width=True)
                
                # ìœ„ì¹˜ ì…ë ¥
                location = st.text_input(
                    "ìœ„ì¹˜",
                    placeholder="ì˜ˆ: ì„œìš¸ì—­",
                    key=f"location_{idx}"
                )
                
                photo_data.append({
                    'image': image,
                    'name': uploaded_file.name,
                    'location': location,
                    'uploaded_file': uploaded_file
                })
        
        st.markdown("---")
        
        # ì €ì¥ ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ’¾ DBì— ì €ì¥í•˜ê¸°", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ê° ì´ë¯¸ì§€ì˜ ì„ë² ë”© ìƒì„±
                for idx, photo in enumerate(photo_data):
                    status_text.text(f"ğŸ¤– AI ì²˜ë¦¬ ì¤‘... ({idx + 1}/{len(photo_data)})")
                    
                    try:
                        # ì„ë² ë”© ìƒì„±
                        embedding = st.session_state.image_finder.get_image_embedding(photo['image'])
                        photo['embedding'] = embedding
                        photo['timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        
                        # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                        img_byte_arr = io.BytesIO()
                        photo['image'].save(img_byte_arr, format='PNG')
                        photo['image_bytes'] = img_byte_arr.getvalue()
                        
                    except Exception as e:
                        st.error(f"âŒ {photo['name']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        continue
                    
                    progress_bar.progress((idx + 1) / len(photo_data))
                
                # ë°ì´í„° ì €ì¥
                st.session_state.saved_photos.extend(photo_data)
                st.session_state.saved_count += len(photo_data)
                
                status_text.empty()
                progress_bar.empty()
                
                # ì„±ê³µ ë©”ì‹œì§€
                st.success(f"âœ… {len(photo_data)}ì¥ì˜ ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.balloons()
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.rerun()

# ==========================================
# ì´ìš©ì ëª¨ë“œ
# ==========================================
else:
    st.markdown("### ğŸ” ìœ ì‚¬ ì‚¬ì§„ ê²€ìƒ‰")
    st.info("ğŸ’¡ ì°¾ê³  ì‹¶ì€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ CLIP ëª¨ë¸ë¡œ ë¹„ìŠ·í•œ ì‚¬ì§„ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤")
    
    # 2ê°œ ì—´ë¡œ ë‚˜ëˆ„ê¸°
    left_col, right_col = st.columns([1, 1])
    
    # ì™¼ìª½: ê²€ìƒ‰ ì„¤ì •
    with left_col:
        st.markdown("#### ğŸ–¼ï¸ ê²€ìƒ‰í•  ì´ë¯¸ì§€")
        search_image = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            type=['png', 'jpg', 'jpeg'],
            key="user_upload"
        )
        
        if search_image:
            image = Image.open(search_image)
            st.image(image, caption="ê²€ìƒ‰í•  ì´ë¯¸ì§€", use_container_width=True)
        
        st.markdown("---")
        
        st.markdown("#### âš™ï¸ ê²€ìƒ‰ ì˜µì…˜")
        
        # ìœ„ì¹˜ í•„í„°
        location_filter = st.text_input(
            "ğŸ“ ìœ„ì¹˜ í•„í„°",
            placeholder="ì˜ˆ: ì„œìš¸ì—­ (ë¹„ì›Œë‘ë©´ ì „ì²´ ê²€ìƒ‰)"
        )
        
        # ê²°ê³¼ ê°œìˆ˜
        top_k = st.slider(
            "ğŸ“Š í‘œì‹œí•  ê²°ê³¼ ê°œìˆ˜",
            min_value=1,
            max_value=20,
            value=5
        )
        
        # ìœ ì‚¬ë„ ìŠ¬ë¼ì´ë”
        similarity_threshold = st.slider(
            "ğŸ¯ ìµœì†Œ ìœ ì‚¬ë„ (%)",
            min_value=0,
            max_value=100,
            value=70,
            help="ë†’ì„ìˆ˜ë¡ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë§Œ í‘œì‹œë©ë‹ˆë‹¤"
        )
        
        st.markdown("---")
        
        # ê²€ìƒ‰ ë²„íŠ¼
        search_button = st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", disabled=not search_image)
    
    # ì˜¤ë¥¸ìª½: ê²€ìƒ‰ ê²°ê³¼
    with right_col:
        st.markdown("#### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
        
        # ê²€ìƒ‰ ì „ ì•ˆë‚´
        if not search_image:
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ê²€ìƒ‰í•´ë³´ì„¸ìš”")
        
        elif search_button:
            if len(st.session_state.saved_photos) == 0:
                st.warning("âš ï¸ ì €ì¥ëœ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‘ê°€ ëª¨ë“œì—ì„œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
            else:
                with st.spinner("ğŸ¤– AIê°€ ìœ ì‚¬ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # ê²€ìƒ‰ ì´ë¯¸ì§€ì˜ ì„ë² ë”© ìƒì„±
                        query_image = Image.open(search_image)
                        query_embedding = st.session_state.image_finder.get_image_embedding(query_image)
                        
                        # ì €ì¥ëœ ëª¨ë“  ì´ë¯¸ì§€ì™€ ìœ ì‚¬ë„ ê³„ì‚°
                        results = []
                        for saved_photo in st.session_state.saved_photos:
                            if 'embedding' not in saved_photo:
                                continue
                            
                            # ìœ„ì¹˜ í•„í„° ì ìš©
                            if location_filter and location_filter.strip():
                                if location_filter.lower() not in saved_photo.get('location', '').lower():
                                    continue
                            
                            # ìœ ì‚¬ë„ ê³„ì‚°
                            similarity = cosine_similarity(query_embedding, saved_photo['embedding'])[0][0]
                            similarity_percent = similarity * 100
                            
                            # ì„ê³„ê°’ í•„í„°
                            if similarity_percent >= similarity_threshold:
                                results.append({
                                    'photo': saved_photo,
                                    'similarity': similarity_percent
                                })
                        
                        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                        results.sort(key=lambda x: x['similarity'], reverse=True)
                        results = results[:top_k]
                        
                        # ê²°ê³¼ í‘œì‹œ
                        if len(results) == 0:
                            st.warning("ğŸ˜” ì¡°ê±´ì— ë§ëŠ” ì‚¬ì§„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.success(f"âœ… **{len(results)}ì¥**ì˜ ìœ ì‚¬í•œ ì‚¬ì§„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                            
                            for idx, result in enumerate(results):
                                with st.container():
                                    col1, col2 = st.columns([1, 2])
                                    
                                    with col1:
                                        # ì €ì¥ëœ ì´ë¯¸ì§€ í‘œì‹œ
                                        result_image = Image.open(io.BytesIO(result['photo']['image_bytes']))
                                        st.image(result_image, use_container_width=True)
                                    
                                    with col2:
                                        st.markdown(f"**#{idx + 1}**")
                                        st.markdown(f"**ğŸ“ {result['photo'].get('location', 'ìœ„ì¹˜ ë¯¸ìƒ')}**")
                                        st.markdown(f"**ğŸ“ {result['photo']['name']}**")
                                        
                                        # ìœ ì‚¬ë„ í‘œì‹œ
                                        similarity_val = result['similarity'] / 100
                                        st.progress(similarity_val)
                                        st.caption(f"ìœ ì‚¬ë„: {result['similarity']:.2f}%")
                                        
                                        # íƒ€ì„ìŠ¤íƒ¬í”„
                                        if 'timestamp' in result['photo']:
                                            st.caption(f"ì—…ë¡œë“œ: {result['photo']['timestamp']}")
                                    
                                    st.markdown("---")
                    
                    except Exception as e:
                        st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# í‘¸í„°
st.markdown("---")
st.caption("ğŸ¤– Powered by OpenAI CLIP Model | ì´ë¯¸ì§€ ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰")